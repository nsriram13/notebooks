{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webcam bounding box detection in notebook\n",
    "\n",
    "Use OpenCV to read webcam feed, use tensorflow do perform bounding box detection and use ipywidgets to display videostream.\n",
    "\n",
    "The TensorFlow detection model is currently the [`ssdlite_mobilenet_v2_coco`](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) pretrained model from the Tensorflow [object detection API](https://github.com/tensorflow/models/tree/master/research/object_detection).\n",
    "\n",
    "This notebook is inspired by the [object detection demo notebook](https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tarfile\n",
    "import zipfile\n",
    "import six.moves.urllib as urllib\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "import threading\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the model from the tensorflow repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threhold used for prediction\n",
    "PREDICT_THRESHOLD = 0.3\n",
    "\n",
    "# What model to download.\n",
    "MODEL_NAME = 'ssdlite_mobilenet_v2_coco_2018_05_09'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_model():\n",
    "    \"\"\"\n",
    "    Download pretrained model from the tensorflow repo\n",
    "    \"\"\"\n",
    "    opener = urllib.request.URLopener()\n",
    "    opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "    tar_file = tarfile.open(MODEL_FILE)\n",
    "    for file in tar_file.getmembers():\n",
    "        file_name = os.path.basename(file.name)\n",
    "        if 'frozen_inference_graph.pb' in file_name:\n",
    "            tar_file.extract(file, os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Downloading model')\n",
    "download_model()\n",
    "print('Model downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model loading functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_graph(model_path):\n",
    "    \"\"\"\n",
    "    Load the downloaded Tensorflow model into memory.\n",
    "    \"\"\"\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.GraphDef()\n",
    "        with tf.gfile.GFile(model_path, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "    return detection_graph\n",
    "\n",
    "\n",
    "def get_tf_tensors(graph):\n",
    "    \"\"\"\n",
    "    Get handles to input and output tensors.\n",
    "    \"\"\"\n",
    "    ops = graph.get_operations()\n",
    "    all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "    tensor_dict = {}\n",
    "    for key in ['detection_boxes', 'detection_scores', 'detection_classes']:\n",
    "        tensor_name = key + ':0'\n",
    "        if tensor_name in all_tensor_names:\n",
    "            tensor_dict[key] = graph.get_tensor_by_name(\n",
    "                tensor_name)\n",
    "    input_image_tensor = graph.get_tensor_by_name('image_tensor:0')\n",
    "    return tensor_dict, input_image_tensor\n",
    "\n",
    "\n",
    "def get_graph_tensors(model_path):\n",
    "    \"\"\"\n",
    "    Load model into memory and get the inputs.\n",
    "    \"\"\"\n",
    "    graph = get_model_graph(model_path)\n",
    "    tensor_dict, input_image_tensor = get_tf_tensors(graph)\n",
    "    return graph, tensor_dict, input_image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebcamBoundingBoxThread(threading.Thread):\n",
    "    \"\"\"\n",
    "    Background thread to read image from webcam, detect objects, and update\n",
    "     interactive display.\n",
    "    \"\"\"\n",
    "    def __init__(self, interactive_img, interactive_framerate_text, model_path):\n",
    "        super(WebcamBoundingBoxThread, self).__init__()\n",
    "        self._stop_event = threading.Event()\n",
    "        self.model_path = model_path\n",
    "        self.interactive_img = interactive_img\n",
    "        self.interactive_framerate_text = interactive_framerate_text\n",
    "        \n",
    "    def setup(self):\n",
    "        \"\"\"\n",
    "        Setup tensorflow graph and webcam connection.\n",
    "        \"\"\"\n",
    "        # Setup Tensorflow detector\n",
    "        (self.detection_graph, self.tensor_dict, \n",
    "         self.input_image_tensor) = get_graph_tensors(self.model_path)\n",
    "        # Setup camera capture\n",
    "        self.camera = cv2.VideoCapture(0)\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"\n",
    "        Stop thread.\n",
    "        \"\"\"\n",
    "        self._stop_event.set()\n",
    "\n",
    "    def stopped(self):\n",
    "        \"\"\"\n",
    "        True iff tread is stopped.\n",
    "        \"\"\"\n",
    "        return self._stop_event.is_set()\n",
    "    \n",
    "    def run_tf_inference(self, image):\n",
    "        \"\"\"\n",
    "        Run tf inference to detect bounding boxes\n",
    "        \"\"\"\n",
    "        output_dict = self.session.run(\n",
    "            self.tensor_dict,\n",
    "            feed_dict={self.input_image_tensor: np.expand_dims(image, 0)})\n",
    "        # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "        output_dict['detection_classes'] = output_dict['detection_classes'][0].astype(np.uint8)\n",
    "        output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "        output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "        return output_dict\n",
    "    \n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"\n",
    "        Process a single frame for bounding box detection.\n",
    "        \"\"\"\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        output_dict = self.run_tf_inference(image)\n",
    "        for i in range(100):\n",
    "            # Assume predictions are ordered by probability\n",
    "            if output_dict['detection_scores'][i] < PREDICT_THRESHOLD:\n",
    "                break\n",
    "            ymin, xmin, ymax, xmax = output_dict['detection_boxes'][i,:]\n",
    "            ymin_pix = int(ymin*image.shape[0])\n",
    "            xmin_pix = int(xmin*image.shape[1])\n",
    "            ymax_pix = int(ymax*image.shape[0])\n",
    "            xmax_pix = int(xmax*image.shape[1])\n",
    "            cv2.rectangle(image, (xmin_pix,ymin_pix), (xmax_pix,ymax_pix), (0,255,0), 3)\n",
    "        return cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Start thread.\n",
    "        Creates loop that reads frame from webcam, detects bounding boxes,\n",
    "         and updates interactive image until thread is stopped.\n",
    "        \"\"\"\n",
    "        self.setup()\n",
    "        is_capturing = self.camera.isOpened()\n",
    "        start_time  = time.time()\n",
    "        with self.detection_graph.as_default():\n",
    "            self.session = tf.Session()\n",
    "            with self.session as sess:\n",
    "                while is_capturing and not self.stopped():\n",
    "                    start_time  = time.time()\n",
    "                    is_capturing, frame = self.camera.read()\n",
    "                    processed_frame = self.process_frame(frame)\n",
    "                    self.interactive_img.value = cv2.imencode('.png', processed_frame)[1].tostring()\n",
    "                    self.interactive_framerate_text.value = '{:.2f}'.format(1/(time.time() - start_time))\n",
    "        self.camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start')\n",
    "# Create interactive image\n",
    "interactive_img = widgets.Image(\n",
    "    value=b'',\n",
    "    format='png',\n",
    "    width=800,\n",
    "    height=600,\n",
    ")\n",
    "\n",
    "# Create interactive text to display framerate\n",
    "interactive_framerate_text = widgets.Text(\n",
    "    value='0',\n",
    "    placeholder='0',\n",
    "    description='Fps:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "# Create thread to update interactive image with webcam\n",
    "print('Setup thread')\n",
    "thread = WebcamBoundingBoxThread(\n",
    "    interactive_img, interactive_framerate_text, PATH_TO_CKPT)\n",
    "thread.daemon = True\n",
    "print('Display image')\n",
    "display(interactive_img)\n",
    "display(interactive_framerate_text)\n",
    "print('Starting thread')\n",
    "thread.start()\n",
    "\n",
    "\n",
    "# Stop thread upon exit\n",
    "print('Running loop')\n",
    "while True:\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        thread.stop()\n",
    "        thread.join()\n",
    "        break\n",
    "\n",
    "        \n",
    "print('Finish')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
